"""
æµ‹è¯•æµå¼è¾“å‡ºåŠŸèƒ½
"""
import asyncio
import logging
from app.ai_service import get_ai_response_stream
from app.config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_streaming():
    """æµ‹è¯•æµå¼è¾“å‡º"""
    print("=" * 50)
    print("æµ‹è¯•æµå¼è¾“å‡ºåŠŸèƒ½")
    print(f"å½“å‰é…ç½®: ENABLE_STREAMING = {settings.ENABLE_STREAMING}")
    print(f"AIæä¾›å•†: {settings.AI_PROVIDER}")
    print("=" * 50)
    
    # æµ‹è¯•æç¤º
    test_prompt = "è¯·ç”¨JSONæ ¼å¼è¿”å›ä¸€ä¸ªç®€å•çš„æ¸¸æˆçŠ¶æ€ï¼ŒåŒ…å«narrativeå’Œstate_updateå­—æ®µ"
    
    # æµ‹è¯•å†å²
    test_history = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆä¸»æŒäºº"},
        {"role": "user", "content": "å¼€å§‹æ¸¸æˆ"}
    ]
    
    print("\nå¼€å§‹æµå¼è¾“å‡ºæµ‹è¯•...")
    print("-" * 30)
    
    full_response = ""
    chunk_count = 0
    
    try:
        async for chunk in get_ai_response_stream(
            prompt=test_prompt,
            history=test_history,
            force_json=True
        ):
            chunk_count += 1
            full_response += chunk
            # æ‰“å°æ¯ä¸ªæ•°æ®å—ï¼ˆä¸ºäº†æ¼”ç¤ºæ•ˆæœï¼‰
            print(f"[Chunk {chunk_count}]: {chunk}", end="", flush=True)
        
        print("\n" + "-" * 30)
        print(f"\næµå¼è¾“å‡ºå®Œæˆ!")
        print(f"æ€»å…±æ¥æ”¶åˆ° {chunk_count} ä¸ªæ•°æ®å—")
        print(f"å®Œæ•´å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
        
        # éªŒè¯JSONæ ¼å¼
        import json
        try:
            # æå–JSONéƒ¨åˆ†
            if "```json" in full_response:
                start = full_response.find("```json") + 7
                end = full_response.find("```", start)
                json_str = full_response[start:end].strip()
            else:
                start = full_response.find("{")
                end = full_response.rfind("}") + 1
                json_str = full_response[start:end]
            
            parsed = json.loads(json_str)
            print("\nâœ… JSONæ ¼å¼éªŒè¯æˆåŠŸ!")
            print(f"è§£æçš„JSONåŒ…å«å­—æ®µ: {list(parsed.keys())}")
        except json.JSONDecodeError as e:
            print(f"\nâŒ JSONæ ¼å¼éªŒè¯å¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {full_response[:200]}...")
            
    except Exception as e:
        print(f"\nâŒ æµå¼è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {e}", exc_info=True)

async def test_normal_response():
    """æµ‹è¯•æ™®é€šï¼ˆéæµå¼ï¼‰å“åº”ä½œä¸ºå¯¹æ¯”"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ™®é€šå“åº”ï¼ˆéæµå¼ï¼‰")
    print("=" * 50)
    
    from app.ai_service import get_ai_response
    
    test_prompt = "è¯·ç”¨JSONæ ¼å¼è¿”å›ä¸€ä¸ªç®€å•çš„æ¸¸æˆçŠ¶æ€ï¼ŒåŒ…å«narrativeå’Œstate_updateå­—æ®µ"
    test_history = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆä¸»æŒäºº"},
        {"role": "user", "content": "å¼€å§‹æ¸¸æˆ"}
    ]
    
    try:
        print("\nå¼€å§‹æ™®é€šå“åº”æµ‹è¯•...")
        response = await get_ai_response(
            prompt=test_prompt,
            history=test_history,
            force_json=True
        )
        
        print(f"å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        print(f"å“åº”é¢„è§ˆ: {response[:200]}...")
        print("\nâœ… æ™®é€šå“åº”æµ‹è¯•æˆåŠŸ!")
        
    except Exception as e:
        print(f"\nâŒ æ™®é€šå“åº”æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {e}", exc_info=True)

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\nğŸš€ å¼€å§‹AIæœåŠ¡æµå¼è¾“å‡ºæµ‹è¯•\n")
    
    # æµ‹è¯•æµå¼è¾“å‡º
    await test_streaming()
    
    # ç­‰å¾…ä¸€ä¸‹
    await asyncio.sleep(2)
    
    # æµ‹è¯•æ™®é€šå“åº”ä½œä¸ºå¯¹æ¯”
    await test_normal_response()
    
    print("\n" + "=" * 50)
    print("âœ¨ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("=" * 50)

if __name__ == "__main__":
    asyncio.run(main())